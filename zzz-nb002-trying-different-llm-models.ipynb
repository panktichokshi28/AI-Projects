{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd35694-5f5a-4d16-8669-ec1f5bf43393",
   "metadata": {},
   "source": [
    "# Connect with alternative LLMs\n",
    "* Talk with Open Source LLMs like Llama3 and Mixtral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4312ba1-de37-450b-89a3-c0b21d955801",
   "metadata": {},
   "source": [
    "## Caveat\n",
    "* Keep in mind that the quality of Llama3 and Mixtral is still below the quality of OpenAI's ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a6bc5-c149-4ef3-a6a7-71fbd72e098a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 002-trying-different-llm-models.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba604a0-5ce9-42b1-92d8-ca8e27e7232b",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d072f-291b-42f3-81ee-bf2c779b2870",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **002-trying-different-llm-models**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5961599-9738-454f-81ad-bb0784f180b4",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398411fd-07b6-4882-9625-e87ec3751da2",
   "metadata": {},
   "source": [
    "## Intro to Groq\n",
    "* Groq is an AI Startup company. **It is not the same as Grok, the LLM from Elon Musk**.\n",
    "* It has developed a new chip call LPU (Language Processing Unit) which is specificly design to run LLMs faster and cheaper.\n",
    "* It offers a Groq Cloud where you can try Open Source LLMs like Llama3 or Mixtral.\n",
    "* **It allows you to use Llama3 or Mixtral in your apps for free using a Groq API Key with some Rate Limits**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a1309-a5f5-4797-aab2-e90d77c2dde5",
   "metadata": {},
   "source": [
    "## How to get a free Groq API Key\n",
    "* Login into Groq Cloud: [https://console.groq.com/login](https://console.groq.com/login)\n",
    "* Once logged in, click on API Keys (left sidebar).\n",
    "* Create a new API Key.\n",
    "* Copy the API Key and paste it in your .env file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c154f-c329-4148-a57d-ed18fcd05d32",
   "metadata": {},
   "source": [
    "## How to install Groq in your project\n",
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you.\n",
    "\n",
    "LangChain has a module for it. We can install it the same way we install other LangChain modules, using PIP or (if we are working in a Poetry app) we can also install it using Poetry. Use one of the following options:\n",
    "* pip install langchain-groq\n",
    "* poetry add langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fad70-2d71-4e4a-b8a6-20285d7eb44f",
   "metadata": {},
   "source": [
    "## How to use Groq in your LangChain or CrewAI project\n",
    "Very easy. Just add the following line at the top of your file:\n",
    "* from langchain_groq import ChatGroq\n",
    "\n",
    "And then, in the code, if you want to use Llama3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce029dd-1e8b-4b82-98f6-bf9bfd09ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"llama3-70b-8192\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f9434-fb9f-4960-af68-55af2d86d847",
   "metadata": {},
   "source": [
    "Or if you want to use Mixtral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2232591-6853-4840-b9d4-4b338a8d81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583dcd83-520b-4dc2-a160-1578314a847e",
   "metadata": {},
   "source": [
    "## You can take a look at Groq Rate limits here\n",
    "* https://console.groq.com/settings/limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4043b0-6f4e-4834-ac5c-8f3c1427c89d",
   "metadata": {},
   "source": [
    "## Groq pricing for projects in Production\n",
    "* [Groq pricing](https://wow.groq.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e299ed0-391d-4578-aee6-2537ce294252",
   "metadata": {},
   "source": [
    "## Let's give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f6a62-115f-4d26-8809-2e604bddd82e",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93ed82f-d41b-4608-83d1-1053573905ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0548e514-cf7a-4f53-8df4-b6c3d03dc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e7309f-3080-4bd0-af0f-374cc642b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8527fb7a-69a1-44ab-9601-e3e259df642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralChatModel = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41aad1b-4aba-4bf4-a06d-2925a68b4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df753975-ebd0-49d0-bd01-56bee372eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaResponse = llamaChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850e5967-ea3a-434a-8aed-406f29ed89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one curious thing about JFK:\n",
      "\n",
      "John F. Kennedy, the 35th President of the United States, was a bestselling author. Yes, you read that right! In 1957, before he became president, JFK wrote a book called \"Profiles in Courage,\" which won the Pulitzer Prize for Biography or Autobiography in 1957.\n",
      "\n",
      "What's curious is that there's been some controversy over the years about how much of the book was actually written by JFK himself. While Kennedy was the credited author, some historians have suggested that he had significant help from his speechwriter, Theodore Sorensen, and possibly even other writers.\n",
      "\n",
      "Despite this controversy, \"Profiles in Courage\" remains a significant work of American history and a testament to JFK's intellectual curiosity and commitment to public service. The book profiles eight U.S. senators who took courageous stands on important issues, often at great personal cost, and it's still widely read and studied today.\n"
     ]
    }
   ],
   "source": [
    "print(llamaResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ce3b58-09d0-431b-95d2-ce9c2fbb5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralResponse = mistralChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f5dc68-4e8d-4006-9354-5d290901b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One curious thing about John F. Kennedy (JFK) is that he suffered from Addison's disease, a rare endocrine disorder that was kept hidden from the public during his presidency. Addison's disease affects the adrenal glands, which produce hormones that regulate various bodily functions, including metabolism and stress response. JFK managed the disease with daily medication and a strict regimen, and it was not disclosed until after his death. This highlights the political dynamics of the time and the extent to which presidential candidates and officials have historically gone to conceal medical conditions from the public.\n"
     ]
    }
   ],
   "source": [
    "print(mistralResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70e41d-5a7a-4831-a1be-978ccaceda07",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 002-trying-different-llm-models.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 002-trying-different-llm-models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d77fd-c1ee-4e13-9219-7b5d16069f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
